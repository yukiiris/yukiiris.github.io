---
layout: post
title: "晋江/长佩小说下载器"
date: 2017-08-11
excerpt: "python爬虫"
tags: [python, spider]
comments: true
---

## 写这个爬虫的原因

&nbsp; &nbsp;  &nbsp; 我第一门学习的编程语言就是python，由于当时缺乏系统的引导没能坚持下来，现在想重新捡起来。之前写过一个Java爬虫，mentor说python爬虫更为简练和迅速，所以尝试一下。前两天刷知乎的时候刚好看到吐槽说小说网站都不提供完结txt下载，遂想到自己写一个。



## 过程

* 准备
  + 用一个小时复习了python的基础语法
  + 学习urllib开源库的常用方法
  + 学习selenium的API
* 开始
  + 参考github上的代码自己封装了一个爬虫引擎
    - page_downloader
    - page_parser
    - page_outputer
  + 分析网页源代码，写出过滤用的正则表达式
  + 获取小说内容，整理小说格式，删除多余内容
  + 研究网站登录机制
  + 尝试模拟登录
  + 获取隐藏章节和vip章节
  + 优化



## 收获

* 踩了无数坑
  + python语法错误而ide又没有提醒
  + chrome的一个恶性bug，第一次超时后再也无法刷新或重新获取网页，而我不知道这是chrome的原因，以为自己写错了，花了很长时间
  + 模拟登录cookie的构造
* 复习了python
* 登录验证和cookie



## 优化

* 获取晋江小说页面的时候，经常会加载一万年，但其实小说内容一般在一两秒内就已经加载完成了，这时候我选择给driver加一个超时设置，时间设为2秒，超时后判断小说内容所在的元素是否加载完成，加载完成即停止整个页面的加载，直接获取页面源码即可，否则再重新获取页面。这样一来，获取每个页面小说内容的时间由五秒至一万年不等到了几秒，极大地优化了爬虫速度。
* 在获取非vip章节时，我原来采用的是phantomjs，但是phantomjs这个没有界面的浏览器其实比有界面的chrome要慢上十倍，果断抛弃换成chrome。



## 不足

- 代码组织乱七八糟
  - 结构上没有好好考虑，这用extend或者implement可以写得条理清晰
  - 没有想到晋江的安全措施这么厉害，把我仅有的代码结构打乱了
  - 常量应该分离出来
- python的语法坑踩了很多，弱类型的语言ide在提示方面比强类型的差了很多
- 性能比较烂，速度大概3s/章
- 有一些奇怪的bug，实在无法解决